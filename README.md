---

# ğŸ“ˆ NSE ETL Pipeline

A lightweight ETL (Extractâ€“Transformâ€“Load) pipeline that downloads symbol master data from **Upstox** and **Dhan**, cleans & transforms it, stores it in **MongoDB** and **SQLite**, and finally generates comparison reports for analysis.

---

## ğŸš€ Features

* **Extract**

  * Fetch Upstox symbol master (gzip CSV)
  * Fetch Dhan symbol master (CSV)
* **Transform**

  * Normalize column names
  * Clean trading symbols (trim, uppercase)
  * Filter required columns
  * Prepare comparison-ready datasets
* **Load**

  * **MongoDB** â†’ Upsert Upstox data (`market_data.upstox_nse`)
  * **SQLite** â†’ Store Dhan data (`db/dhan_data.db`)
* **Compare**

  * Find differences between Upstox & Dhan symbol lists
  * Generate 3 reports:

    * `common_stocks.csv`
    * `only_in_upstox.csv`
    * `only_in_dhan.csv`

---

## ğŸ“¦ Project Structure

```
NSE_ETL_PIPELINE/
â”‚â”€â”€ db/
â”‚   â”œâ”€â”€ dhan_data.db
â”‚   â”œâ”€â”€ mongo_setup.py
â”‚   â””â”€â”€ sql_setup.sql
â”‚
â”‚â”€â”€ etl/
â”‚   â”œâ”€â”€ extract.py
â”‚   â”œâ”€â”€ transform.py
â”‚   â”œâ”€â”€ load.py
â”‚   â”œâ”€â”€ compare.py
â”‚   â”œâ”€â”€ test_extract.py
â”‚   â”œâ”€â”€ test_transform.py
â”‚   â””â”€â”€ __pycache__/
â”‚
â”‚â”€â”€ output/
â”‚   â”œâ”€â”€ common_stocks.csv
â”‚   â”œâ”€â”€ only_in_upstox.csv
â”‚   â””â”€â”€ only_in_dhan.csv
â”‚
â”‚â”€â”€ main.py
â”‚â”€â”€ README.md
â”‚â”€â”€ requirements.txt
â””â”€â”€ .venv/
```

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/<your-username>/nse_etl_pipeline.git
cd nse_etl_pipeline
```

### 2ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

---

## ğŸ—„ï¸ Prerequisites

### âœ” MongoDB

The pipeline loads Upstox data into MongoDB.

Ensure MongoDB is running on:

```
mongodb://localhost:27017/
```

If using Docker:

```bash
docker run -d -p 27017:27017 --name mongo mongo:6.0
```

### âœ” SQLite

No setup needed â€” the SQLite database (`db/dhan_data.db`) is created automatically.

---

## â–¶ï¸ Run the Pipeline

```bash
python main.py
```

This will:

* Download fresh symbol master files
* Apply transformations
* Load data into MongoDB & SQLite
* Compare both datasets
* Generate CSV reports inside the `output/` folder

---

## ğŸ“¤ Output Files

| File                   | Description                           |
| ---------------------- | ------------------------------------- |
| **common_stocks.csv**  | Symbols present in both Upstox & Dhan |
| **only_in_upstox.csv** | Symbols present only in Upstox        |
| **only_in_dhan.csv**   | Symbols present only in Dhan          |

---

## ğŸ”‘ Key Assumptions

* **Trading symbol (`SEM_TRADING_SYMBOL`) is treated as the unique identifier** while comparing.
* Dataset formats from Upstox & Dhan follow their documented schema.
* MongoDB will auto-create the database (`market_data`) and collection (`upstox_nse`) during upsert operations.

---

## ğŸ§ª Testing

Basic tests for extract & transform logic:

```bash
pytest
```

---

## ğŸ›  Future Enhancements

* Add logging & monitoring for ETL pipeline
* Add incremental updates (avoid full reload)
* Enable cloud database support (Mongo Atlas / Postgres)
* Add Docker Compose for full environment setup
* Integrate Airflow / Prefect for scheduling

---

## ğŸ¤ Contributing

Feel free to open issues or submit PRs!

---
